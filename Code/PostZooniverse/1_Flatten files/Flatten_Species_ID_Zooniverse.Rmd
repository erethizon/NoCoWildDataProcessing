---
title: "Flattening our Zooniverse files"
output: html_notebook
---
## Overview
Output from classifications on the [Zooniverse](https://zooniverse.com) come encoded in *JSON format*.  While most of the columns are straightforward to interpret, two critical columns are not.  The first is the **annotation column**.  Within it are the species identification and the answers to all of the questions for each event. Likewise, the **subject_data** column contains all of the information from the manifest, such as the forest type, photo batch, camera number, and forest name.  It would be good to be able to pull all of this information. We especially need it if we plan to remove e.g. images taken on malfunctioning cameras or otherwise suspect images.
 
Processing the data requires six steps:
1. Selecting the correct classification file from among many. We peridically download classification files from the Zooniverse, and keep them all in the same folder. We use the `choose_my_class-file` function to allow the user to input the classification file that they would like to process.

2. Isolating the data from a single workflow number and workflow version so that all fields are compatible. We use the custom  `choose_my_workflow` function to allow the user to select the workflow number and version and return a dataset that has been reduced to that single workflow version.

3. Parsing the annotations column.

4. Parsing the subject_data column.

5. Merge the annotations & subject_data to a data frame for data analysis via a join command.

6. Write the output to a folder called "Flattened" in the PostZooniverse Output folder.

THIS FILE IS FOR PARSING THE JSON DATA FROM THE "SPECIES IDENTIFICATION" WORKFLOWS. USE THE FILE "FLATTEN_IS_THERE_ANIMAL_ZOONIVERSE.RMD" TO PARSE ANIMAL PRESENCE/ABSENCE DATA.

### Turn on packages and bring in the data and r scripts
We need to load desired packages and also source custom functions  so that they will run. The tidyjson package may have to be loaded from this [github](https://github.com/sailthru/tidyjson) site. Look [here](https://cran.r-project.org/web/packages/githubinstall/vignettes/githubinstall.html) for some hints as to how to do that.

```{r, message=FALSE, echo=FALSE}
rm(list = ls())
library(here)
library(tidyverse)
library(tidyjson)#may get error; if so, load from github
library(jsonlite)
library(magrittr) #allows piping beyond tidyverse
library(dplyr)
library(stringr)
library(tidyr)
library(lubridate)
library(rstudioapi)

myFunctions<-list.files(here("Code", "Functions"), pattern = "R") 
#points to files that need to be sourced

sapply(here("Code", "Functions", myFunctions), source) #sources all of the functions in the Functions folder.
```

###Step 1. Choose the classification file to work with.
We have multiple classification files. The choose_file_isol asks the user for input so that they can select the classification file to work with. The classification file should be on the t://drive in Bart_s04/Research_group/NoCoWild/Data/classification_files.

Try with the `choose_file_isolate_workflow` function

```{r}
DF<-choose_file_isolate_workflow()
data<-DF[[1]]
filename<-DF[[2]]
```

###Step 2. Limit to appropriate portion of workflow
A single workflow might contain classifications of data from multiple projects, so we need to subset it to just the project we are looking for. 

So here we can subset to the start date you want. Note that the start date is not the date the pictures were taken but is the date the classifications were made.
```{r}
data<-narrow_to_date(data)
```

### Step 3. Parse the annotations column
We now flatten the Annotations column by calling the  `flatten_annotations` function. 

```{r}
flat_file<-flatten_annotations(data) #this is slow; could we write faster code?  A problem for another day.
```

### Step 4. Parse the subjects column

Now we can parse the data.

```{r}
subjects<-flatten_subjects(data)
```

I've updated flatten_subjects so that it reports a lot of columns, parsing all of the subject columns regardless of the format of the manifest that was uploaded to the zooniverse. So now we can sort by project and isolate data from different manifests that use the same workflow. 


Notice that if flat_file has fewer rows than subjects it is because for some subset of the data (equal in number to the difference in length b/w the subjects data and the flat_file data) no identification was made, so the annotations column has no information.

###Step 4. Merge the annotations and subjects data
Now that we have flattened both the annotations and subject_data columns, we would like to generate one large data frame with all of the data to export and analyze (using different R scripts!).  To do so, we need to join the two data frames.  Joining will **only work** if you have a column, named identically in both data frames, on which the join will work.

The join itself is pretty easy:
```{r}
Flattened<-left_join(flat_file, subjects, by='classification_id')
```
Now move subject_ids column to left most position
```{r}
Flattened<-Flattened %>% relocate(subject_ids)
```

Now Save our result! This will go in the flattened folder within the PostZooniverse outputs.
```{r}
output<-here("Output", "PostZooniverse", "Flattened")

myFile<-str_remove(filename, ".csv") #drop the .csv temporarily

write.csv(Flattened,  paste0(output, "/","wkfl_16695_29.1","_flat_", Sys.Date(), ".csv"))

```



