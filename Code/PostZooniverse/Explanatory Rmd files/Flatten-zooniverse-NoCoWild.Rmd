 ---
title: "Flattening our Zooniverse files"
output: html_notebook
---
##Overview
Output from classifications on the [Zooniverse](https://zooniverse.com) come encoded in *JSON format*.  While most of the columns are straightforward to interpret, two critical columns are not.  The first is the **annotation column**.  Within it are the species identification and the answers to all of the questions for each event. Likewise, the **subject_data** column contains all of the information from the manifest, such as the forest type, photo batch, camera number, and forest name.  It would be good to be able to pull all of this information.

Processing the data requires four steps:
1. Isolating the data from a single workflow number and workflow version so that all fields are compatible.

2. Parsing the annotations column.

3. Parsing the subject_data column.

4. Merge the annotations & subject_data to a data frame for data analysis via a join command.

Some of these process are accomplished using scripts provided on the zooniverse github page, modified to fit our data.  Other processes we coded ourselves. Some of that is noted below.

### Turn on packages and bring in the data and r scripts
We need to load desired packages and also source the zooniverse scripts so that they will run. The tidyjson package may have to be loaded from this [github](https://github.com/sailthru/tidyjson) site. Look [here](https://cran.r-project.org/web/packages/githubinstall/vignettes/githubinstall.html) for some hints as to how to do that.

```{r}
rm(list = ls())
library(tidyjson) #may get error; if so, load from github
library(magrittr) #allows piping beyond tidyverse
library(jsonlite)
library(dplyr)
library(stringr)
library(tidyr)
library(lubridate)

source(file = "flattening_script.R")
source(file = "flattening_functions.R")
#this two calls load the zooniverse functions to the workspace; note that if either is not in the same folder as this code, you need to specify the file path.
```
If needed, use this code to install tidyjson from github:
```{r}
#library(githubinstall)
#githubinstall("tidyjson")
```

###Step 1. Isolating the data to a single workflow and version number
A zooniverse project can have multiple work flows, and each workflow can have multiple versions. Now that we have prepared the workspace,we need to clean the classification data to focus on just the workflow number and version that we want.

To do so, we need to define variables that will be used in the run_json_parsing function. They need the names as below.

**Required variables**: You **need to define these** or the script could break.
jdata <- character()
survey_id <- character()
workflow_id_num <- numeric()
workflow_version_num <- numeric(). 

Define required variables:
```{r}
jdata <- character()
survey_id <- character()
workflow_id_num <- numeric()
workflow_version_num <- numeric()

```
####Specify Project
Give the project a name and id the classifications file
```{r}
project_name <- "NoCoWild"
#classifications_file <- "/Users/ebar/Dropbox/R/JSON/no-co-wild-phase-1-_1Apr_classifications.csv" #from Erika's laptop; change path as needed to access from another computer

#classifications_file<-
#"/Volumes/External #Drive/Dropbox/R/JSON/no-co-wild-phase-1-_1Apr_classifications.csv"

classifications_file<- "~/Dropbox/R/NoCoWild/Data/north-country-wild-classifications.csv"
```
####Examine data
```{r}
jdata <- read.csv(classifications_file, stringsAsFactors = F)
```
#### Set project-specific details
```{r}
check_workflow(jdata) %>% View
workflow_id_num <- 16695
workflow_version_num <- 11.80
```
#### Limit to relevant workflow id and version
```{r}
jdata <- jdata %>% filter(., workflow_id == workflow_id_num, workflow_version == workflow_version_num)
```
###Step 2. Parse the annotations column

#### Identify task-specific details. 
(Notes from whoever wrote this originally for Zooniverse: These variable names are important, because I haven't figured out how to define them in the function call; there's some weird referencing. I don't know. The function definitions and scripts could be improved, but things seem to generally work)

Examine the data to see how it is structured 
```{r}
jdata$annotations[1] %>% prettify
```
Use the output from the last call to properly fill these out:
```{r}
#View_json(jdata)
survey_id <- c("T0")#determine from prettify
single_choice_Qs <-  c("choice", "HOWMANY", "ESTIMATEOFSNOWDEPTHSEETUTORIALORFIELDGUIDE", "ANTLERSPRESENT") #determine from prettify call
single_choice_colnames  <-  c("choice","Number", "SnowDepth", "Antlers")#determine from View_json call
multi_choice_Qs <- c("WHATBEHAVIORSDOYOUSEE")#determine from View_json call
multi_choice_colnames <- c("behavior")#determine from View_json call

```

#### Now flatten the file
We now flatten the Annotations column by calling the code from the flattening_functions file. 

**If you want to combine multiple workflows or multiple tasks before aggregating, this is the time to do it.**

```{r}
An_flattened <- run_json_parsing(data = jdata) #requires flattening_functions file to be in same folder and sourced.
#this only works with tidyjson installed.  Need a fix.
View(An_flattened)
```
This result may give more rows than are in the original (*jdata*) data file.  If so, it is because the same subject was classified as two different species.  There will be more than one total submissions for the particularl classification id's. This will be important for joining the annotation data with the subject data below.

###Step 3. Parse the subjects column
#### Examine subject_data details.
Examine one of the JSON subject_data entries using "prettify"

```{r}
jdata$subject_data[1] %>% prettify
```
R returns the first element from the subject_data column.  

####Convert subject_data to list
Next we need to tell R that jdata$subject_data should be a list (currently is is viewed as character data). We are going to make a list called subjects:

```{r}
subjects<-purrr::map(jdata$subject_data, jsonlite::fromJSON, flatten = T)
#this brought in the subject_data as a list where it now shows up in the environment

```
Now let's try to get some of the information from that list; for example, we'd like to know the habitat, forest type, camera number and sd card number from the subject data:

```{r}
ForestType<-sapply(subjects, function(x)x[[1]]$`!ForestType`, simplify = T)
ForestName<-sapply(subjects, function(x)x[[1]]$`#ForestName`, simplify = T)
Image1<-sapply(subjects, function(x)x[[1]]$`Image1`, simplify = T)
Image2<-sapply(subjects, function(x)x[[1]]$`Image2`, simplify = T)
Image3<-sapply(subjects, function(x)x[[1]]$`Image3`, simplify = T)
Camera<-sapply(subjects, function(x)x[[1]]$`#CamNumber`, simplify = T)
SDCard<-sapply(subjects, function(x)x[[1]]$`#SDCardNum`, simplify = T)
PhotoBatch<-sapply(subjects, function(x)x[[1]]$`!Batch`, simplify = T)
Class_Round<-sapply(subjects, function(x)x[[1]]$`!Round`, simplify = T)
```
Now we have all of the subject data as individual varaibles.  We should patch them all together in a data frame, and include the classification_id and subject_id from jdata as well so that we can easily keep track of which row of subject data goes with which subjects. Start with some of the data from jdata:
```{r}
classification_id<-jdata$classification_id
subject_ids<-jdata$subject_ids
user_name<-jdata$user_name
workflow_id<-jdata$workflow_id
workflow_version<-jdata$workflow_version
```

Now make a dataframe of all of the subject data now that it is flattened (note the several vars we pulled from jdata in doing so)

```{r}
Sub_flattened<-as.data.frame(cbind(classification_id, user_name, workflow_id, workflow_version, ForestType, ForestName, Image1, Image2, Image3, Camera, SDCard, PhotoBatch, Class_Round))
```
Note that Sub_flattened has the same number of records as jdata.  This number may be smaller than the number rendered in An_flattened.  

###Step 4. Merge the annotations and subjects data
Now that we have flattened both the annotations and subject_data columns, we would like to generate one large data frame with all of the data to export and analyze (using different R scripts!).  To do so, we need to join the two data frames.  Joining will **only work** if you have a column, named identically in both data frames, on which the join will work.

The join itself is pretty easy and uses the plyr package:
```{r}
library(plyr)
Flattened<-join(An_flattened, Sub_flattened, by='classification_id', type='right', match='all')
```

Now Save our result!
```{r}
Filename<-str_sub(classifications_file,end = -4)
write.csv(Flattened, paste0(classifications_file,"-flattened.csv"), row.names = F)
```
