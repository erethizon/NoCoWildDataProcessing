---
title: "Exploring flattened data"
output: html_notebook
---

The end product of the flattening process is a new dataset that includes all of the species identifications and metadata associated with each event. We need to take those data and explore them to determine how well the classifications were made.

```{r}
rm(list = ls())
library(tidyverse)
library(here)
```
Pull in data
```{r}
CWMM<-read.csv(here("Code", "PostZooniverse","2022-June", "Data", "CWMM.csv"))
DS<-read.csv(here("Code", "PostZooniverse","2022-June", "Data", "DS.csv"))
KA<-read.csv(here("Code", "PostZooniverse","2022-June", "Data", "KA.csv"))
Meta<-read.csv(here("Code", "PostZooniverse","2022-June", "Data", "Meta.csv"))
```
Let's reduce the dataframes to common columns, combine then and then use for analysis.

```{r}
DS$Source<-"DS"
KA$Source<-"KA"
CWMM$Source<-"CWMM"
```
Need to now get a list of the columns I want to keep from each dataset so that I can create the columns in some data sets as needed for joining later.

From CWMM I want:
subject_ids
classification_id
user_name
workflow_name
workflow_version
choice
created_at
round
Img1
Img2
Img3
CamNum
SD_card_num
For_name
For_type
CamSD
Phase
Forest
Treatment
DTO
Source



Set things up for looping through each dataframe and repeating the same steps using purrr. Need to put all the dataframes into a list

```{r}

mydfs<-list(DS, KA, CWMM)
#now create function that does things I need
clean_em_up<-function(df){
 df<-df %>% select(!c(X.1, X))
  df<-df %>% select(c(Source,subject_ids:workflow_version, choice, created_at, Img1, Img2, Img3, CamSD, For_name))
}
mydfs<-mydfs %>% map(clean_em_up)
 
```

Now combine those 3 list items into a single data frame using bind_rows from tidyverse
```{r}
All<-bind_rows(mydfs)
```


How many observations per subject_id?
```{r}
Meta$mean_obs_per_subject<- NA
obs_per_subject<-mydfs %>% 
  map(
    function(df){
      df<-df %>% group_by(subject_ids) %>% summarise(
      obs_per_subject = length(choice)) 
      })
mean_ops<-obs_per_subject %>% map(
  function(df){
    df<-df %>% select(obs_per_subject)
    mean_ops<-mean(df$obs_per_subject, na.rm = T)
    
    })
Meta$mean_obs_per_subject<-mean_ops %>% map(pluck,1)

```
What is the range in number of classifications per subject id?
```{r}
Meta$min_obs_per_subject<- NA
obs_per_subject<-mydfs %>% 
  map(
    function(df){
      df<-df %>% group_by(subject_ids) %>% summarise(
      obs_per_subject = length(choice)) 
      })
min_ops<-obs_per_subject %>% map(
  function(df){
    df<-df %>% select(obs_per_subject)
    min_ops<-min(df$obs_per_subject, na.rm = T)
    
    })
Meta$min_obs_per_subject<-min_ops %>% map(pluck,1)


Meta$max_obs_per_subject<- NA
obs_per_subject<-mydfs %>% 
  map(
    function(df){
      df<-df %>% group_by(subject_ids) %>% summarise(
      obs_per_subject = length(choice)) 
      })
max_ops<-obs_per_subject %>% map(
  function(df){
    df<-df %>% select(obs_per_subject)
    max_ops<-max(df$obs_per_subject, na.rm = T)
    
    })
Meta$max_obs_per_subject<-max_ops %>% map(pluck,1)
```

Now see if I can join the date-time of each object for each image from the camera exif data. I created a master DTO sheet to attempt with.

Read in the exif data
```{r}
exif<-read.csv(here("Data", "masterDTO.csv"))
exif$FileName2<-exif$FileName
```
Now try to join to All

```{r}
Main<-left_join(All, exif, by = c("Img1" = "FileName2"))
```
Now dump some columns to make it easier to look at
```{r}
Main<-Main %>% select(!c(FileSize, ImageSize, FocalLength, ShutterSpeed, Aperture, ISO, WhiteBalance, Flash))
```
And now relocate things
```{r}
Main<-Main %>% relocate(CamSD.y, .after = CamSD.x)
Main<-Main %>% relocate(DateTimeOriginal,.before = created_at)
Main<-Main %>% relocate(FileName, .before = user_name)
```
Now I can also look at which workflows were associated with which batches of pictures. To do so, I'm going to get sub-dataframes from Main that correspond to year and Round

```{r}
unique(Main$Year)
```







