---
title: "Exploring flattened data"
output: html_notebook
---

The end product of the flattening process is a new dataset that includes all of the species identifications and metadata associated with each event. We need to take those data and explore them to determine how well the classifications were made.

```{r}
rm(list = ls())
library(tidyverse)
library(here)
```
Pull in data
```{r}
df<-read.csv(here("Output", "PostZooniverse","Processed","all_data_to_June2022.csv"))
```

What is the range in number of classifications per subject id?
```{r}
Class_summary<-df %>% group_by(Student, subject_ids) %>% summarise(
  NumClass=length(classification_id)
)

length(unique(df$subject_ids))
```
There are 15,344 subjects in the dataset

How many classifications?
```{r}
length(unique(df$classification_id))
n_distinct(df$classification_id)
```
There are a few classifications (83724-83387 = 337) that appear more than once. Why?

Let's look at them.

```{r}
df<-df %>% group_by(classification_id) %>% mutate(
  dupe = n()> 1)
ungroup(df)
check<-df %>% filter(dupe == TRUE)
```
So there are 337 cases in which there was > 1 animal observed in the subject. Cool. Looks good.


Now see if I can join the date-time of each object for each image from the camera exif data. I created a master DTO sheet to attempt with.

Read in the exif data
```{r}
exif<-read.csv(here("Data", "masterDTO.csv"))
exif$FileName2<-exif$FileName
```

```{r}
Main<-left_join(df, exif, by = c("Img1" = "FileName2"))
```
Now dump some columns to make it easier to look at
```{r}
Main<-Main %>% select(!c(FileSize, ImageSize, FocalLength, ShutterSpeed, Aperture, ISO, WhiteBalance, Flash))
```
And now relocate things
```{r}
Main<-Main %>% relocate(CamSD.y, .after = CamSD.x)
Main<-Main %>% relocate(DateTimeOriginal,.before = created_at)
Main<-Main %>% relocate(FileName, .before = user_name)
```

When I was working with this before, I was losing some of the info from maggie's data. Take a look:

```{r}
Main %>% filter(Student == "Maggie") %>% View()

```
Why is there one row in Maggie's data that looks like it is from a different dataset?  Check it out

```{r}
Main %>% filter(FileName == "14_22_DON_000031.JPG") %>% View()
```

For some reason it was classified again in Maggie's protocol - but we don't need it there, so I'm going to delete the one instance of it that corresponds to Maggie's data.
```{r}
find<-which(Main$FileName == "14_22_DON_000031.JPG" & Main$Student == "Maggie")
Main<-Main[-c(find),]
```
Now move workflow ID next to workflow version
```{r}
Main <-Main %>% relocate(workflow_id, .after = workflow_name)
```

Ok, now let's see if we can get all the forest names the same
```{r}
unique(Main$Forest)
```
Ok, let's do full forest names

```{r}
don<-which(Main$Forest == "DON")
Main$Forest[don]<-"Donnerville"
deg<-which(Main$Forest == "DEG")
Main$Forest[deg]<-"Degrasse"

bc<-which(Main$Forest == "BC")
Main$Forest[bc]<-"Beaver Creek"

sh<-which(Main$Forest == "SH")
Main$Forest[sh]<-"South Hammond"

wf<-which(Main$Forest == "WF")
Main$Forest[wf]<-"Whisky Flats"

whip<-which(Main$Forest == "WHIP" |Main$Forest == "Whip")
Main$Forest[whip]<-"Whippoorwill"

unique(Main$Forest)
```
Now fix round numbers
```{r}
unique(Main$round)
```
Make them all R1 or R2
```{r}
r1<-which(Main$round == "1")
Main$round[r1]<- "R1"

r2<-which(Main$round == "2")
Main$round[r2]<- "R2"

unique(Main$round)
```
Check more vars
```{r}
unique(Main$batch) #ok
unique(Main$CamNumber)
```
Find the cam nums that begin with "C"
```{r}
fix<-which(str_detect(Main$CamNumber, "C"))
View(Main[fix,])
#now pull the C off

Main$CamNumber[fix]<-str_replace(Main$CamNumber[fix], "C0", "0")
#now get rid of leading zeros
Main$CamNumber[fix]<-str_remove(Main$CamNumber[fix], "^0+")
Main$CamNumber<-as.numeric(Main$CamNumber)
Main$CamSD.z<-paste0(Main$CamNumber,"-", Main$SDNumber)
Main<-Main %>% relocate(CamSD.z, .after = CamSD.y)
```
Now forest type
```{r}
unique(Main$For_type)
fixpines<-which(Main$For_type == "Pine ")
Main$For_type[fixpines]<-"Pine"
fixdecid<-which(Main$For_type == "Deciduous ")
Main$For_type[fixdecid]<-"Deciduous"
unique(Main$For_type)
```
Fix phase - combine phase 1 batch 1 and phase 1 batch 2 as "experiment"

```{r}
exp<-which(Main$Phase == "phase 1 batch 1"| Main$Phase == "phase 1 batch 2")

Main$Phase[exp]<-"experiment"
unique(Main$Phase)
```
check Treatment
```{r}
unique(Main$Treatment)
```
Need to combine Snap and Snapshot
```{r}
snap<-which(Main$Treatment == "Snap")
Main$Treatment[snap]<-"Snapshot"
unique(Main$Treatment)
```

Now move Cam_SD next to CamSD.z, Cam and SD after CamNumber, SDNumber
```{r}
Main<-Main %>% relocate(Cam_SD, .after = CamSD.z)
Main<-Main %>% relocate(Cam, .after = SDNumber) %>% relocate(SD, .after = Cam)
Main<-Main  %>% relocate(Year, .after = DTO) %>% relocate(Model, .after =CamMod) %>% relocate(dupe, .after = retire.date)
Main<-Main %>% select(-X)
```
How many subjects were not fully classified on zooniverse?

```{r}
Unclassed<-Main %>% filter(is.na(class.count))
```
Basically, Donovan's data were uploaded to zooniverse but not completely classified in the workflow. Are there any images from Donovan's data set that don't also appear elsewhere?

To check, subtract Donovan's from Main (= Unclassed) and then make a dataset that just includes classified images.

```{r}
Classed<-Main %>% filter(!is.na(class.count))
```
Now see how many of the subject ids from Unclassed are in Classed
```{r}
InBoth<-which(Unclassed$subject_ids %in% Classed$subject_ids)
unique(Classed$Student)
```
All of the data from Donovan's subset are already present in Kates' so I'm going to delete them from Main.

```{r}
dump<-which(Main$Student == "Donovan")
Main<-Main[-dump,]
```

Ok, now take a look at some of the descriptive stats again

What is the range in number of classifications per subject id?
```{r}
Class_summary<-Main %>% group_by(Student, subject_ids) %>% summarise(
  NumClass=length(classification_id)
)

length(unique(df$subject_ids))
```
There are 15,344 subjects in the dataset

How many classifications?
```{r}
length(unique(Main$classification_id))
n_distinct(Main$classification_id)
```

```{r}
Main<-Main %>% group_by(classification_id) %>% mutate(
  dupe = n()> 1)
ungroup(Main)
check<-Main %>% filter(dupe == TRUE)
```
So there is a subset of images for which the date time original is different for the same image (not possible)-perhaps a problem in the exif data?

Take a look
```{r}
exif %>% group_by(CamSD) %>% summarise(
  numYears = n_distinct(Year),
) %>% View()
```
Each CamSD was only present in a single year. So that's good.

```{r}
CheckDTO<-Main %>% group_by(subject_ids,classification_id ) %>% summarise(
  num_DTOs = n_distinct(DateTimeOriginal)
)

#grab subject and classification ids for those with > 1 date

weird_dates<-CheckDTO %>% filter(num_DTOs > 1)
```
There are 229 observations for which a combination of subject_id and classification_id had more than one date. Let's look at them from Main

```{r}
fixDates<-Main %>% filter(subject_ids %in% weird_dates$subject_ids & classification_id %in% weird_dates$classification_id) 
```
There are 458 rows (which makes sense - 229*2). Let's see what we can about them.

```{r}
unique(fixDates$Student)
```
They all come from Kate's dataset. Let's look at which files have two different date times in exif.

```{r}
bad_exif<-exif %>% group_by(FileName) %>% summarise(
  numDTO = n_distinct(DateTimeOriginal)
)
var<-bad_exif %>% filter(numDTO > 1)
check<-exif %>% filter(FileName %in% var$FileName)
```
Ok! Looked on disc, and these are situations where there were pictures with the same file name but different dates - so these are in fact NOT the same subjects. How to fix?

I'm going to add a column called "new_sub_id" which will be the original subject ID for all but the second batch of images (from Round 3) which will get a "-3" added to the subject id

```{r}
Main <- Main %>% mutate(
  new_sub_id = subject_ids
)
Main<-Main %>% relocate(new_sub_id, .after = subject_ids)
```
Now figure out the subject_ids that need an added indicator. It is all the ones in fixDates with Round = 3.

Let's see if we can find them in Main
```{r}
fix<-which(Main$subject_ids %in% fixDates$subject_ids & Main$classification_id %in% fixDates$classification_id & Main$Round == 3)
```
229 rows long.  Good! Now fix those subject_ids

```{r}
Main$new_sub_id[fix]<-paste0(Main$subject_ids[fix],"-", Main$Round[fix])
```
Great! That fixed it. Now I can save this as the master data set.

And I think we've got it!  Let's save this as the master up through June, 2022.

```{r}
write.csv(Main, here("Output", "PostZooniverse","Processed", "master_class_file_to_June2022.csv"))
```













